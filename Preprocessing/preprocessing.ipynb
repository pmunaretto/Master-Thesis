{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Information\n","\n","**Author:**<br>Pascal Munaretto (<a href=\"mailto:pascal.munaretto@outlook.com\">Mail</a>)\n","\n","**Date:**<br>30.09.2022\n","\n","**Type:**<br>Master's Thesis\n","\n","**Topic:**<br>Design, Implementation and Performance Analysis of an AI-Based Insider Threat Detection Platform\tin Splunk To Counteract Data Exfiltration\n","\n","**Study Program:**<br>Enterprise and IT Security\n","\n","**Institution:**<br><a href=\"https://www.hs-offenburg.de\">Offenburg University of Applied Sciences</a>\n","\n","**Github:**<br>https://github.com/pmunaretto/Master-Thesis"],"metadata":{"id":"v2M3HAr1_DcJ"}},{"cell_type":"markdown","source":["# Check GPU"],"metadata":{"id":"djet7nO9TmDm"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSDTsOv0eN9u","executionInfo":{"status":"ok","timestamp":1655694867640,"user_tz":-120,"elapsed":18,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"outputId":"fcaea919-2fc4-4864-827b-7675750112a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Jun 20 03:14:27 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"KgXZQgApTt0L"}},{"cell_type":"markdown","source":["## Requirements"],"metadata":{"id":"x9PkXR2h2aHS"}},{"cell_type":"markdown","source":["First, Conda is installed by using a custom instructor. Prepackaging Conda reduces the installation time from ~25 minutes to ~6 minutes.\n","\n","**Channels:**\n","- rapidsai\n","- nvidia\n","- conda-forge\n","\n","**Specs:**\n","- python=3.7\n","- cudatoolkit=11.2\n","- llvmlite\n","- gcsfs\n","- openssl\n","- dask-sql\n","- pip\n","- conda\n","- mamba"],"metadata":{"id":"mCvD4fkNVyAW"}},{"cell_type":"code","source":["!pip install -q condacolab\n","import condacolab\n","condacolab.install_from_url(\"file:/content/drive/MyDrive/condacolab-0.1-Linux-x86_64.sh\")"],"metadata":{"id":"tx3HEpGZ-cYh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install line_profiler\n","!pip install memory_profiler\n","%load_ext line_profiler\n","%load_ext memory_profiler"],"metadata":{"id":"NtbrQTb31I1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Imports"],"metadata":{"id":"HfovDuwPyzRr"}},{"cell_type":"code","source":["import dask_cudf\n","import glob\n","import json\n","import requests\n","import os\n","import re\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"xL_6Hg8Sywg5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Configuration"],"metadata":{"id":"_fBlVCLE0CPC"}},{"cell_type":"code","source":["BASE_PATH = \"/content/drive/MyDrive/CERT/r4.2\""],"metadata":{"id":"hFLXRPK10DUe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preparation"],"metadata":{"id":"FkwEU6zI2Set"}},{"cell_type":"markdown","source":["## Get a List of Job Sites"],"metadata":{"id":"nGt0qdE12NHt"}},{"cell_type":"code","source":["import requests\n","import re"],"metadata":{"id":"lUuj5s6q6ZTR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["r = requests.get(\"https://raw.githubusercontent.com/emredurukn/awesome-job-boards/master/README.md\")\n","job_portals = re.findall(\"http[s]?:\\/\\/(?:www.)?(?!github|cdn\\.rawgit)([^:\\/\\s)]+)\", r.text)\n","print(f\"Amount of Job Portals: {len(job_portals)}\")\n","print(f\"Job Portals: {job_portals}\")"],"metadata":{"id":"QthiKIxE0haz","executionInfo":{"status":"ok","timestamp":1655697156413,"user_tz":-120,"elapsed":455,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c1b5d6ac-ddbb-4def-cd2f-58cf06fcd81b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Amount of Job Portals: 342\n","Job Portals: ['linkedin.com', 'indeed.com', 'glassdoor.com', 'angel.co', 'datajobs.com', 'ai-jobs.net', 'jobhunt.ai', 'icrunchdata.com', 'kdnuggets.com', 'datayoshi.com', 'jobs.opendatascience.com', 'jobsnew.analyticsvidhya.com', 'jobsfornewdatascientists.com', 'bigdatajobs.com', 'statsjobs.com', 'bigcloud.global', 'data-stryde.com', 'blocktribe.com', 'cryptojobslist.com', 'crypto.jobs', 'blockew.com', 'cryptocurrencyjobs.co', 'useweb3.xyz', 'block-stryde.com', 'nextcryptojobs.com', 'designjobs.aiga.org', 'authenticjobs.com', 'behance.net', 'coroflot.com', 'ixda.org', 'dribbble.com', 'krop.com', 'opensourcedesign.net', 'uxjobsboard.com', 'designerjobs.co', 'designmodo.com', 'designjobsboard.com', 'jobs.designweek.co.uk', 'designjobs.aiga.org', 'ifyoucouldjobs.com', 'creativemornings.com', 'creativepool.com', 'theloop.com.au', 'ninjajobs.org', 'infosec-jobs.com', 'cybersecurityjobsite.com', 'careersincyber.com', 'careersinfosecurity.com', 'cybersecurityjobs.net', 'jobs.yeswehack.com', 'cyber-stryde.com', 'thecarrots.io', 'ClojureJobboard.com', 'goopensource.dev', 'iosdevjobs.com', 'elixir-radar.com', 'elixirjobs.net', 'frontenddeveloperjob.com', 'fullstackjob.com', 'functionaljobs.com', 'golangprojects.com', 'welovegolang.com', 'forum.golangbridge.org', 'golangjob.xyz', 'golang.cafe', 'angularjobs.com', 'angular.work', 'jobs.emberjs.com', 'vuejobs.com', 'madewithvuejs.com', 'react-jobs.com', 'reactjobboard.com', 'reactjsjob.com', 'rustjob.xyz', 'weloveangular.com', 'weworkmeteor.com', 'jobs.drupal.org', 'jobs.wordpress.net', 'larajobs.com', 'wphired.com', 'python.org', 'pythonjob.xyz', 'pythonjobshq.com', 'djangogigs.com', 'djangojobs.net', 'jobs.rubynow.com', 'rorjobs.com', 'rust-jobs.com', 'webassemblyjobs.com', 'jobs.date-fns.org', 'jobsinjs.com', 'r-users.com', 'careervault.io', 'remotebond.com', 'jobspresso.co', 'weworkremotely.com', 'workaline.com', 'remotive.io', 'remote.com', 'remoteok.io', 'justremote.co', 'skipthedrive.com', 'remote.co', 'remote4me.com', 'workingnomads.co', 'europeremotely.com', 'awesomejobs.io', 'remotepython.com', 'rubyonremote.com', 'remoteml.com', 'jsremotely.com', 'remotearena.com', 'letsworkremotely.com', 'workew.com', 'wellpaid.io', 'nodesk.co', 'flexjobs.com', 'rmtwrk.com', 'remotify.me', 'remoters.net', 'jobmote.com', 'remotelyawesomejobs.com', 'dailyremote.com', 'remote-developer-jobs.com', 'remotees.com', 'meerkad.com', 'workfromhomejobs.me', 'pangian.com', 'outsourcely.com', 'prospercircle.org', 'dynamitejobs.com', 'flatworld.co', 'beefrii.com', 'hireremote.io', 'remoteindex.co', 'smoothremote.com', 'upwork.com', 'toptal.com', 'freelancer.com', 'guru.com', 'peopleperhour.com', 'fiverr.com', 'talent.hubstaff.com', 'outsource.com', 'giggrabbers.com', 'cloudpeeps.com', 'localsolo.com', 'yunojuno.com', 'gun.io', 'monster.com', 'jobs.github.com', 'amazon.jobs', 'news.ycombinator.com', 'stackoverflow.com', 'crunchboard.com', 'jobs.hackernoon.com', 'jobbatical.com', 'powertofly.com', 'whoishiring.io', 'simplyhired.com', 'careerbuilder.com', 'careercast.com', 'dice.com', 'jobs.techstars.com', 'producthunt.com', 'ziprecruiter.com', 'idealist.org', 'aquent.com', 'hackerx.org', 'findwork.dev', 'jobs.livecareer.com', 'themuse.com', 'linkup.com', 'authenticjobs.com', 'devsnap.io', 'joblist.app', 'jobs2careers.com', 'jobisjob.com', 'joblift.com', 'adzuna.com', 'techmeabroad.com', 'hackerrank.com', 'findbacon.com', 'codersrank.io', 'reddit.com', 'jora.com', 'hnhiring.com', 'nocsok.com', 'ycombinator.monday.vc', 'relocate.me', 'producthire.net', 'sportekjobs.com', 'epicjobs.co', 'able.bio', 'stackshare.io', 'neuvoo.com', 'toplanguagejobs.com', 'vanhack.com', 'calmjobs.io', 'peoplefirstjobs.com', 'naukri.com', 'jobs.digitaloxford.com', 'css-tricks.com', 'smashingmagazine.com', 'totaljobs.com', 'xing.com', 'codepen.io', 'jobs.theguardian.com', 'jobsinnetwork.com', 'snagajob.com', 'roberthalf.com', 'higheredjobs.com', 'mediabistro.com', 'joblist.com', 'workatastartup.com', 'enviro.work', 'f6s.com', 'theladders.com', 'cleverism.com', 'virtualvocations.com', 'jobs.mashable.com', 'jobvertise.com', 'equalopportunity.work', 'jobs.cncf.io', 'kdrrecruitment.com', 'diversifytech.co', 'womenwhocode.com', 'hitmarker.net', 'careers.greatercph.com', 'heygamer.co', 'jobs.prsa.org', 'efinancialcareers.com', 'uncubed.com', 'healthecareers.com', 'techfetch.com', 'launchafrica.io', 'diversityjobs.com', 'clearancejobs.com', 'itjobpro.com', 'the-dots.com', 'campaignlive.co.uk', 'goodjobs.careers', 'techjobsforgood.com', 'waitwhatdoyoudo.com', 'getwork.com', 'lensa.com', 'arbeitnow.com', '4dayweek.io', 'entryleveljobs.me', 'collegerecruiter.com', 'internships.com', 'jrdevjobs.com', 'graduateland.com', 'talentegg.ca', 'entrylevel.io', 'erasmusintern.org', 'careerrookie.com', 'aftercollege.com', 'startup.jobs', 'startupers.com', 'workinstartups.com', 'thehub.io', 'unicornhunt.io', 'startuphire.com', 'workinbiotech.com', 'austechjobs.com.au', 'seek.com.au', 'careerone.com.au', 'jobaroo.com', 'breakout.careers', 'headhunted.com.au', 'workintech.ca', 'to9to5.com', 'jobboom.com', 'jobillico.com', 'jobbank.gc.ca', 'eluta.ca', 'careerbeacon.com', 'jobsite.co.uk', 'jobserve.com', 'wiredsussex.com', 'cwjobs.co.uk', 'reed.co.uk', 'cv-library.co.uk', 'itjobswatch.co.uk', 'gumtree.com', 'analyticsjobs.co.uk', 'wikijob.co.uk', 'devitjobs.uk', 'jobsintown.de', 'stepstone.de', 'jobvector.de', 'jobware.de', 'stellenanzeigen.de', 'jobs.de', 'stellenonline.de', 'berlinstartupjobs.com', 'jobsinberlin.eu', 'germantechjobs.de', 'jobinamsterdam.com', 'hoitalent.com', 'togetherabroad.nl', 'jobindex.dk', 'it-jobbank.dk', 'jobsincopenhagen.com', 'state-of-denmark.com', 'careersinpoland.com', 'crossweb.pl', 'bulldogjob.com', 'justjoin.it', 'swissdevjobs.ch', 'WeJob.ch', 'jobwinner.ch', 'jobscout24.ch', 'landing.jobs', 'workinestonia.com', 'cvkeskus.ee', 'jobs.zalando.com', 'euroengineerjobs.com', 'nofluffjobs.com', 'duunitori.fi', 'jobbland.se', 'nijobs.com', 'hyperisland.com', 'findwrk.app', 'kodilan.com', 'randstad.com.tr', 'startupjobs.istanbul', 'toptalent.co', 'dallasjobs.io', 'us.jobs', 'careerjet.com', 'nexxt.com', 'usnlx.com', 'juju.com', 'techjobsasia.com', 'fossjobs.net', 'oo.t9t.io', 'linuxjobs.io', 'jobsfordevops.com', 'kube.careers', 'growthhackers.com']\n"]}]},{"cell_type":"code","source":["job_portals = pd.read_csv(os.path.join(BASE_PATH, \"job_portals.csv\"))[\"url\"].to_list()"],"metadata":{"id":"cf39z8Ipju0w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get a List of Malicious Event IDs"],"metadata":{"id":"wsiNJW3r2xRx"}},{"cell_type":"code","source":["# Get the path of all answers files\n","files = glob.glob(os.path.join(BASE_PATH, \"answers/r4.2/*.csv\"))\n","\n","# Create an empty list for malicious event ids\n","answers = []\n","\n","# Iterate through each file and extract the id of the malicious event\n","for f in files:\n","    with open(f, \"rb\") as infile:\n","        for line in infile:\n","            line = line.decode().split(\",\")[1]\n","            line = line.replace(\"\\\"\",\"\")\n","            answers.append(line)\n","\n","answers[:10]"],"metadata":{"id":"WXM4Pxp22szH","executionInfo":{"status":"ok","timestamp":1655697190793,"user_tz":-120,"elapsed":33955,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d874402f-d18c-49e8-dae5-627e8dbfb996"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['{Q4V8-Q7GY61AR-5156JFIN}',\n"," '{Y4R1-Z8TY05GU-7397GLKY}',\n"," '{A7Y6-T2ZM78RE-3085IFRU}',\n"," '{R4U0-L5EY71BN-9432WLPE}',\n"," '{L7V8-B3VF10NY-3528JHMD}',\n"," '{J0W5-D1UM54UE-1226CKXX}',\n"," '{T4O3-W9NH72UI-2778USIL}',\n"," '{P3P3-R5NS04UU-2644BJIC}',\n"," '{I2P1-S9MC06AP-9989GDDO}',\n"," '{I7C2-D6NT66AA-1853AICO}']"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Get Additional Information about Each User (Role, Team, ...)"],"metadata":{"id":"1600uj4b23jF"}},{"cell_type":"code","source":["from sklearn.preprocessing import LabelEncoder\n","import dask.dataframe as dd\n","import cudf\n","\n","# Reading the first LDAP file is enough since it contains information about all 1000 employees\n","user_mapping = pd.read_csv(os.path.join(BASE_PATH, \"ldap/2009-12.csv\"), usecols=[\"user_id\", \"role\", \"functional_unit\", \"department\", \"team\"])\n","user_mapping[\"functional_unit\"] = user_mapping[\"functional_unit\"].str[:1].fillna(0).astype(\"int\")\n","user_mapping[\"department\"] = user_mapping[\"department\"].str[:1].fillna(0).astype(\"int\")\n","user_mapping[\"team\"] = user_mapping[\"team\"].str[:1].fillna(0).astype(\"int\")\n","user_mapping[\"role\"] = LabelEncoder().fit_transform(user_mapping[\"role\"])\n","user_mapping.rename(columns={\"user_id\": \"user\"}, inplace=True)\n","user_mapping.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EnxWPTBd5ad6","executionInfo":{"status":"ok","timestamp":1655697192009,"user_tz":-120,"elapsed":1228,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"outputId":"c8641cce-bd23-421c-83f5-1be5e5fe4920"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 5 columns):\n"," #   Column           Non-Null Count  Dtype \n","---  ------           --------------  ----- \n"," 0   user             1000 non-null   object\n"," 1   role             1000 non-null   int64 \n"," 2   functional_unit  1000 non-null   int64 \n"," 3   department       1000 non-null   int64 \n"," 4   team             1000 non-null   int64 \n","dtypes: int64(4), object(1)\n","memory usage: 39.2+ KB\n"]}]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"FX3DW6yf20mS"}},{"cell_type":"code","source":["# Iterate through the datasets\n","for filename in glob.glob(os.path.join(BASE_PATH, \"*.csv\"))[::-1]:\n","\n","    print(f\"Processing {filename}...\")\n","\n","    # Read the CSV as a dask cudf dataframe, parsing the dates is faster...\n","    df = dask_cudf.read_csv(filename, parse_dates=[\"date\"], chunksize=\"2GB\")\n","\n","    # Add threat labels\n","    df[\"threat\"] = 0\n","    df[\"threat\"] = df.threat.where(~df.id.isin(answers), 1)\n","\n","    # Extrct the hours and weekdays from the datetime and map it to sin/cos\n","    df[\"hour\"] = df.date.dt.hour\n","    df[\"weekday\"] = df.date.dt.isocalendar().day\n","    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"]/23.0)\n","    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"]/23.0)\n","    df[\"weekday_sin\"] = np.sin(2 * np.pi * df[\"weekday\"]/7)\n","    df[\"weekday_cos\"] = np.cos(2 * np.pi * df[\"weekday\"]/7)\n","\n","    # Drop the id column\n","    df = df.drop(columns=[\"id\"])\n","\n","    # HTTP specific preprocessing\n","    if os.path.basename(filename) == \"http.csv\":\n","        df[\"url\"] = df[\"url\"].str[7:].str.split(\"/\", n=1, expand=True)[0]\n","        df[\"is_job_portal\"] = 0\n","        df[\"is_job_portal\"] = df.is_job_portal.where(~df.url.isin(job_portals), 1)\n","        df = df.drop(columns=[\"content\"])\n","\n","    # Convert the dask cudf dataframe to a dask dataframe\n","    df = df.map_partitions(lambda df: df.to_pandas())\n","\n","    # Add the user role/functional_unit/department/team information\n","    df = df.merge(user_mapping, on=[\"user\"])\n","\n","    # Save the modified dataframe in parquet which is more efficient to read/write\n","    if not os.path.exists(os.path.join(BASE_PATH, \"preprocessed\")):\n","        os.makedirs(os.path.join(BASE_PATH, \"preprocessed\"))\n","\n","    # Finally, save the dataframe to the new subdirectory\n","    df.to_parquet(\n","        f\"{os.path.join(BASE_PATH, 'preprocessed', os.path.splitext(os.path.basename(filename))[0])}\",\n","        write_index=False,\n","        compression=None\n","    )"],"metadata":{"id":"01wnHUJPMNtw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1655697381514,"user_tz":-120,"elapsed":189508,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"outputId":"488c7a2f-9a20-4d35-cbbd-9b98c66c15bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Processing /content/drive/MyDrive/CERT/r4.2/http.csv...\n"]}]},{"cell_type":"markdown","source":["# Data Augmentation"],"metadata":{"id":"i7ezlwIN8lEc"}},{"cell_type":"markdown","source":["## Helper Function"],"metadata":{"id":"WCxUHxc-OCip"}},{"cell_type":"code","source":["def transform_features_to_sessions(df, open_activity, close_activity):\n","\n","    # Use a counter so we do not have to start the inner loop from the beginning\n","    checkpoint = 0\n","    \n","    # Accumulating the sessions in a list is cheaper than appending to a dataframe\n","    sessions = []\n","\n","    # Iterate through the grouped dataframe\n","    for i in range(0, df.shape[0] - 1):\n","\n","        row1 = df.iloc[i]\n","        row2 = df.iloc[i+1]\n","\n","        if row1.activity == open_activity and row2.activity == close_activity:\n","\n","            # Calculate the time delta and convert it to minutes\n","            session_duration = row2.date - row1.date\n","            session_duration = int(session_duration.total_seconds() / 60)\n","\n","            # Append the session information to the list\n","            sessions.append(\n","                list(row1) + [session_duration]\n","            )\n","\n","    # Transform the list to a dataframe and return it \n","    return pd.DataFrame(sessions, columns=list(df) + [\"session_duration\"])"],"metadata":{"id":"E3-3QF093FnW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Logon Sessions"],"metadata":{"id":"eUQlhMBgN8nL"}},{"cell_type":"code","source":["%%time\n","\n","# Read the logon data\n","df = pd.read_parquet(os.path.join(BASE_PATH, \"preprocessed\", \"logon\"))\n","\n","# Group the dataframe by users\n","session_df = df.groupby(\"user\").apply(\n","    transform_features_to_sessions,\n","    open_activity=\"Logon\",\n","    close_activity=\"Logoff\"\n",")\n","\n","# Save the session data to a new parquet\n","session_df.to_parquet(\n","    os.path.join(BASE_PATH, \"preprocessed\", \"logon_sessions\"),\n","    index=False,\n","    engine=\"pyarrow\",\n","    compression=None\n",")"],"metadata":{"id":"5ROEcWZy8nVR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Device Sessions"],"metadata":{"id":"rrA-HERKN-vI"}},{"cell_type":"code","source":["%%time\n","%%memit\n","\n","# Read the device data\n","df = pd.read_parquet(os.path.join(BASE_PATH, \"preprocessed\", \"device\"))\n","\n","# Group the dataframe by users\n","session_df = df.groupby(\"user\").apply(\n","    transform_features_to_sessions,\n","    open_activity=\"Connect\",\n","    close_activity=\"Disconnect\"\n",")\n","\n","# Save the session data to a new parquet\n","session_df.to_parquet(\n","    os.path.join(BASE_PATH, \"preprocessed\", \"device_sessions\"),\n","    index=False,\n","    engine=\"pyarrow\",\n","    compression=None\n",")"],"metadata":{"id":"GYpKts2r8oba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651966964160,"user_tz":-120,"elapsed":613495,"user":{"displayName":"Pascal Munaretto","userId":"15390274654486759460"}},"outputId":"c49dc4c3-2d47-4b42-eab5-048a8110fc9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["peak memory: 3782.61 MiB, increment: 97.56 MiB\n","CPU times: user 10min 13s, sys: 5.13 s, total: 10min 18s\n","Wall time: 10min 13s\n"]}]}]}